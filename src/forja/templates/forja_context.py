#!/usr/bin/env python3
# FORJA_TEMPLATE_VERSION=0.1.0
"""Forja Context Store - persistent variables outside Claude Code's context window.

Teammates and the lead use this to store and read decisions that survive compactions.

Usage:
    python3 .forja-tools/forja_context.py get <key>
    python3 .forja-tools/forja_context.py set <key> <value> --author <name> [--tags <t1,t2>]
    python3 .forja-tools/forja_context.py list [prefix]
    python3 .forja-tools/forja_context.py search <term>
    python3 .forja-tools/forja_context.py manifest
    python3 .forja-tools/forja_context.py health
    python3 .forja-tools/forja_context.py history <key>
    python3 .forja-tools/forja_context.py export --prefix <prefix> --output <file>
    python3 .forja-tools/forja_context.py probe

Storage: context/store/*.json
"""

try:
    import fcntl
    HAS_FCNTL = True
except ImportError:
    HAS_FCNTL = False
import json
import os
import sys
import tempfile
import time
from datetime import datetime, timezone
from pathlib import Path

STORE_DIR = Path("context/store")
HISTORY_DIR = STORE_DIR / ".history"
LOCK_FILE = STORE_DIR / ".lock"
ONTOLOGY_FILE = Path("context/ontology.md")

LOCK_TIMEOUT = 5
LOCK_RETRIES = 3


# ── File locking ─────────────────────────────────────────────────────

class StoreLock:
    """Context manager for file locking. Uses fcntl on Unix, no-op on Windows."""

    def __init__(self):
        self._fd = None

    def __enter__(self):
        STORE_DIR.mkdir(parents=True, exist_ok=True)
        if not HAS_FCNTL:
            return self
        self._fd = open(LOCK_FILE, "w")

        for attempt in range(LOCK_RETRIES):
            try:
                fcntl.flock(self._fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
                return self
            except (IOError, OSError):
                if attempt < LOCK_RETRIES - 1:
                    time.sleep(LOCK_TIMEOUT / LOCK_RETRIES)
                else:
                    self._fd.close()
                    print("ERROR: Could not acquire lock after 3 attempts")
                    sys.exit(1)
        return self

    def __exit__(self, *args):
        if self._fd and HAS_FCNTL:
            fcntl.flock(self._fd, fcntl.LOCK_UN)
            self._fd.close()


# ── Helpers ──────────────────────────────────────────────────────────

def _key_to_filename(key):
    """Convert a dotted key to a safe filename."""
    return key.replace("/", "__").replace(" ", "_") + ".json"


def _load_var(key):
    """Load a variable file. Returns dict or None."""
    path = STORE_DIR / _key_to_filename(key)
    if not path.exists():
        return None
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, OSError):
        return None


def _atomic_write(path, data_str):
    """Write a file atomically using tempfile + rename."""
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp_fd, tmp_path = tempfile.mkstemp(dir=str(path.parent), suffix=".tmp")
    try:
        with os.fdopen(tmp_fd, "w") as f:
            f.write(data_str)
        os.rename(tmp_path, str(path))
    except BaseException:
        os.unlink(tmp_path)
        raise


def _save_var(data):
    """Save a variable file atomically."""
    STORE_DIR.mkdir(parents=True, exist_ok=True)
    path = STORE_DIR / _key_to_filename(data["key"])
    _atomic_write(path, json.dumps(data, indent=2, ensure_ascii=False) + "\n")


def _all_vars():
    """Load all variables sorted by key."""
    STORE_DIR.mkdir(parents=True, exist_ok=True)
    results = []
    for f in STORE_DIR.glob("*.json"):
        try:
            data = json.loads(f.read_text(encoding="utf-8"))
            if "key" in data:
                results.append(data)
        except (json.JSONDecodeError, OSError):
            continue
    return sorted(results, key=lambda d: d["key"])


def _save_history(key, data):
    """Append a version to history."""
    HISTORY_DIR.mkdir(parents=True, exist_ok=True)
    hist_file = HISTORY_DIR / (_key_to_filename(key).replace(".json", "") + ".json")

    history = []
    if hist_file.exists():
        try:
            history = json.loads(hist_file.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, OSError):
            history = []

    history.append(data)
    _atomic_write(hist_file, json.dumps(history, indent=2, ensure_ascii=False) + "\n")


def _update_ontology():
    """Regenerate context/ontology.md from all variables."""
    variables = _all_vars()
    lines = ["# Context Ontology", "", "Auto-generated by forja_context.py. Do not edit manually.", ""]

    for var in variables:
        key = var["key"]
        val = var["value"]
        author = var.get("author", "?")
        version = var.get("version", 1)
        tags = ", ".join(var.get("tags", []))

        val_str = json.dumps(val, ensure_ascii=False) if isinstance(val, (dict, list)) else str(val)
        if len(val_str) > 80:
            val_str = val_str[:77] + "..."

        tag_part = f" [{tags}]" if tags else ""
        lines.append(f"- **{key}**: {val_str} (v{version}, by {author}){tag_part}")

    _atomic_write(ONTOLOGY_FILE, "\n".join(lines) + "\n")


def _compact_value(val, max_len=60):
    """Compact a value for display."""
    if isinstance(val, (dict, list)):
        s = json.dumps(val, ensure_ascii=False)
    else:
        s = str(val)
    if len(s) > max_len:
        return s[:max_len - 3] + "..."
    return s


def _parse_value(raw):
    """Try to parse value as JSON, fall back to string."""
    try:
        return json.loads(raw)
    except (json.JSONDecodeError, TypeError):
        return raw


# ── Commands ─────────────────────────────────────────────────────────

def cmd_get(args):
    """Read a variable's value."""
    if len(args) < 1:
        print("ERROR: Missing key")
        sys.exit(1)

    key = args[0]
    data = _load_var(key)
    if data is None:
        print(f"ERROR: Key '{key}' not found")
        sys.exit(1)

    val = data["value"]
    if isinstance(val, (dict, list)):
        print(json.dumps(val, indent=2, ensure_ascii=False))
    else:
        print(val)


def cmd_set(args):
    """Create or update a variable."""
    if len(args) < 2:
        print("ERROR: Missing key and/or value")
        sys.exit(1)

    key = args[0]
    raw_value = args[1]

    # Parse flags
    author = "unknown"
    tags = []
    i = 2
    while i < len(args):
        if args[i] == "--author" and i + 1 < len(args):
            author = args[i + 1]
            i += 2
        elif args[i] == "--tags" and i + 1 < len(args):
            tags = [t.strip() for t in args[i + 1].split(",") if t.strip()]
            i += 2
        else:
            i += 1

    value = _parse_value(raw_value)
    now = datetime.now(timezone.utc).isoformat()

    with StoreLock():
        existing = _load_var(key)
        version = (existing["version"] + 1) if existing else 1

        data = {
            "key": key,
            "value": value,
            "author": author,
            "version": version,
            "created_at": existing["created_at"] if existing else now,
            "updated_at": now,
            "tags": tags if tags else (existing.get("tags", []) if existing else []),
        }

        # Save history before overwriting
        if existing:
            _save_history(key, existing)

        _save_var(data)
        _update_ontology()

    action = "updated" if version > 1 else "created"
    print(f"{key}: {action} (v{version} by {author})")


def cmd_list(args):
    """List keys matching a prefix."""
    prefix = args[0] if args else ""
    variables = _all_vars()
    matches = [v for v in variables if v["key"].startswith(prefix)]

    if not matches:
        print("No variables" + (f" with prefix '{prefix}'" if prefix else ""))
        return

    for var in matches:
        val_str = _compact_value(var["value"])
        print(f"  {var['key']}: {val_str}")

    print(f"\n{len(matches)} variable{'s' if len(matches) != 1 else ''}")


def cmd_search(args):
    """Search keys and values for a term."""
    if not args:
        print("ERROR: Missing term")
        sys.exit(1)

    term = args[0].lower()
    variables = _all_vars()
    matches = []

    for var in variables:
        key_match = term in var["key"].lower()
        val_str = json.dumps(var["value"], ensure_ascii=False) if isinstance(var["value"], (dict, list)) else str(var["value"])
        val_match = term in val_str.lower()
        tag_match = any(term in t.lower() for t in var.get("tags", []))

        if key_match or val_match or tag_match:
            matches.append(var)

    if not matches:
        print(f"No results for '{args[0]}'")
        return

    for var in matches:
        val_str = _compact_value(var["value"])
        print(f"  {var['key']}: {val_str}  (by {var.get('author', '?')})")

    print(f"\n{len(matches)} result{'s' if len(matches) != 1 else ''}")


def cmd_manifest(args):
    """Print compact summary of all variables (<500 tokens)."""
    variables = _all_vars()

    if not variables:
        print("(no variables in context store)")
        return

    for var in variables:
        val_str = _compact_value(var["value"], max_len=80)
        author = var.get("author", "?")
        version = var.get("version", 1)
        print(f"{var['key']}: {val_str} (by {author}, v{version})")


def cmd_health(args):
    """Show store health stats."""
    variables = _all_vars()

    if not variables:
        print("Context store is empty")
        return

    count = len(variables)
    versions = [v.get("version", 1) for v in variables]
    avg_version = sum(versions) / len(versions)

    timestamps = []
    for v in variables:
        ts = v.get("updated_at") or v.get("created_at")
        if ts:
            timestamps.append(ts)

    last_update = max(timestamps) if timestamps else "?"

    # Count by author
    authors = {}
    for v in variables:
        a = v.get("author", "unknown")
        authors[a] = authors.get(a, 0) + 1

    print("Context Store Health")
    print("====================\n")
    print(f"  Variables:           {count}")
    print(f"  Last updated:        {last_update}")
    print(f"  Average version:     {avg_version:.1f}")
    print(f"  Authors:             {len(authors)}")
    for author, n in sorted(authors.items()):
        print(f"    {author}: {n} variable{'s' if n != 1 else ''}")


def cmd_history(args):
    """Show version history for a key."""
    if not args:
        print("ERROR: Missing key")
        sys.exit(1)

    key = args[0]
    hist_file = HISTORY_DIR / (_key_to_filename(key).replace(".json", "") + ".json")

    # Load history
    history = []
    if hist_file.exists():
        try:
            history = json.loads(hist_file.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, OSError):
            pass

    # Also include current version
    current = _load_var(key)

    if not history and current is None:
        print(f"ERROR: Key '{key}' not found")
        sys.exit(1)

    print(f"History for: {key}\n")

    for entry in history:
        val_str = _compact_value(entry["value"])
        ts = entry.get("updated_at", entry.get("created_at", "?"))
        print(f"  v{entry.get('version', '?')}  {ts}  by {entry.get('author', '?')}")
        print(f"      {val_str}")

    if current:
        val_str = _compact_value(current["value"])
        ts = current.get("updated_at", current.get("created_at", "?"))
        print(f"  v{current.get('version', '?')}  {ts}  by {current.get('author', '?')}  ← current")
        print(f"      {val_str}")

    total = len(history) + (1 if current else 0)
    print(f"\n{total} version{'s' if total != 1 else ''}")


def cmd_export(args):
    """Export variables matching prefix to a JSON file."""
    prefix = ""
    output = ""
    i = 0
    while i < len(args):
        if args[i] == "--prefix" and i + 1 < len(args):
            prefix = args[i + 1]
            i += 2
        elif args[i] == "--output" and i + 1 < len(args):
            output = args[i + 1]
            i += 2
        else:
            i += 1

    if not output:
        print("ERROR: Missing --output <file>")
        sys.exit(1)

    variables = _all_vars()
    matches = [v for v in variables if v["key"].startswith(prefix)]

    export_data = {
        "exported_at": datetime.now(timezone.utc).isoformat(),
        "prefix": prefix or "(all)",
        "count": len(matches),
        "variables": matches,
    }

    _atomic_write(Path(output), json.dumps(export_data, indent=2, ensure_ascii=False) + "\n")
    print(f"Exported {len(matches)} variables to {output}")


def cmd_probe(args):
    """Show last 3 modified variables as a verification prompt."""
    variables = _all_vars()

    if not variables:
        print("PROBE: No variables in context store")
        return

    # Sort by updated_at descending
    def sort_key(v):
        return v.get("updated_at") or v.get("created_at") or ""

    recent = sorted(variables, key=sort_key, reverse=True)[:3]

    parts = []
    for var in recent:
        val_str = _compact_value(var["value"], max_len=40)
        parts.append(f"{var['key']}={val_str}")

    print(f"PROBE: Verify these decisions are still valid: {', '.join(parts)}")


# ── Main ─────────────────────────────────────────────────────────────

COMMANDS = {
    "get": cmd_get,
    "set": cmd_set,
    "list": cmd_list,
    "search": cmd_search,
    "manifest": cmd_manifest,
    "health": cmd_health,
    "history": cmd_history,
    "export": cmd_export,
    "probe": cmd_probe,
}

USAGE = """Usage:
  python3 .forja-tools/forja_context.py get <key>
  python3 .forja-tools/forja_context.py set <key> <value> --author <name> [--tags <t1,t2>]
  python3 .forja-tools/forja_context.py list [prefix]
  python3 .forja-tools/forja_context.py search <term>
  python3 .forja-tools/forja_context.py manifest
  python3 .forja-tools/forja_context.py health
  python3 .forja-tools/forja_context.py history <key>
  python3 .forja-tools/forja_context.py export --prefix <prefix> --output <file>
  python3 .forja-tools/forja_context.py probe"""


def main():
    if len(sys.argv) < 2 or sys.argv[1] not in COMMANDS:
        print(USAGE)
        sys.exit(1)

    command = sys.argv[1]
    COMMANDS[command](sys.argv[2:])


if __name__ == "__main__":
    main()
